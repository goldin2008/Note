# engineering-project

## Data Engineer

高强度专业培训第一阶段：Big Data Infrastructure强化训练
第一阶段目标：搭建一个实时的数据分析平台。

第一个月将会从最基础的大数据框架出发，分析它们的优势劣势，学习当前业界最火的系统架构，并将其应用到我们的项目当中，从而构建出一个高性能的实时数据分析平台。同学们将使用AWS，搭建起属于自己的云服务并使用Docker技术，简单快速拥有属于自己大数据平台。从数据采集，到利用NoSql数据库数据存储(Cassandra)，到数据传输(Kafka)，再到数据分析(Spark)和最终的数据展示(Nodejs)。学员将经历一个完整的高性能数据pipeline的搭建。同时也将使用(Zookeeper)以保证平台的高可用性和(Redis)以达到工作压力的合理分配。在这一个月中对于每一个技术，我们都将深究其内部原理，做到知其然，还知其所以然，而不是简单的利用API的调用。

高强度专业培训--第一阶段 Big Data Infrastructure强化训练
     第一阶段目标：搭建一个实时的数据分析平台。

     第一个月将会从最基础的大数据框架出发，分析它们的优势劣势，学习当前业界最火的系统架构，并将其应用到我们的项目当中，从而构建出一个高性能的实时数据分析平台。同学们将使用AWS，搭建起属于自己的云服务并使用Docker技术，简单快速拥有属于自己大数据平台。从数据采集，到利用NoSql数据库数据存储(Cassandra)，到数据传输(Kafka)，再到数据分析(Spark)和最终的数据展示(nodejs)。学员将经历一个完整的高性能数据pipeline的搭建。同时也将使用(Zookeeper)以保证平台的高可用性和(Redis)以达到工作压力的合理分配。在这一个月中对于每一个技术，我们都将深究其内部原理，做到知其然，还知其所以然，而不是简单的利用API的调用。



课程具体安排如下：

     第一周

          1. 学习和了解大数据开源技术

          2. 了解大数据内涵及分布式系统

          3. 了解Apache Zookeeper，Docker

          4. 理解AWS的基本原理

          5. 在命令行中使用Apache Zookeeper，Kafka

          6. 用kafka实现data ingestion layer

   

     第二周 

          1. 了解NoSQL，Apache HBase，Apache Cassandra技术

          2. 进一步学习AWS的使用

          3. 在命令行中使用HBase，Cassandra

          4. 用Cassandra实现data storage layer

          5. 在AWS上部署Zookeeper，Kafka，Cassandra

     

     第三周 

          1. 理解Big Data Computing技术的起源

          2. 学习并了解Apache Spark

          3. 在命令行中使用Spark

          4. 用Spark Streaming library和Spark运行data computation layer

     

     第四周 

          1. 学习并理解Node.js及Apache Mesos (内部原理)

          2. 了解single vs multi threads的区别

          3. 了解Sync io vs async io的区别

          4. 在命令行使用Redis，Node.js

          5. 使用Redis，Node.js运行data visualization layer

          6. 在AWS上部署Mesos，Spark
          
          
高强度专业培训第二阶段：Apache开源项目强化训练
第二阶段目标：熟练掌握基于Hadoop的数据分析，Hadoop的基本Use Case和Pig/Hive的编程，有真实大数据系统的实战经验，同时还将具备开源软件的开发能力。

第二个月我们将着重训练同学们对Apache系列软件的应用及开发能力。我们将从Hadoop生态系统的主要项目介绍开始，先从熟悉DFS、MapReduce、Tez, Zookeeper、Pig、Hive、Oozie, Sqoop、Flume、HBase、Phoenix、Ambari、Nutch、Zeppelin等工具的理解及应用开始逐渐建立对Hadoop的更深层理解，能清楚理解Hadoop能解决什么问题，ETL的基本操作以及如何用Pig实现ETL，如何用Hive做数据分析，在此之上更希望同学能主动思考，提出对软件的自我理解，成为Apache的Contributor。

高强度专业培训--第二阶段 Apache开源项目强化训练
     第二阶段目标：熟练掌握基于Hadoop的数据分析，Hadoop的基本Use Case，Pig/Hive的编程，有真实大数据系统的实战经验，同时还将具备开源软件的开发能力。

     第二个月我们将着重训练同学们对Apache系列软件的应用及开发能力。我们将从Hadoop生态系统的主要项目介绍开始，先从熟悉DFS, MapReduce, Tez, Zookeeper, Pig, Hive, Oozie, Sqoop, Flume, HBase, Phoenix, Ambari, Nutch, Zeppelin等工具的理解及应用开始逐渐建立对Hadoop的更深层理解，能清楚理解Hadoop能解决什么问题，ETL的基本操作以及如何用Pig实现ETL，如何用Hive做数据分析，在此之上更希望同学能主动思考，提出对软件的自我理解，成为Apache的Contributor。



课程具体安排如下：

     第一周

          1. 什么是Hadoop？

          2. Hadoop的历史 

          3. Hadoop主要Use Case

          4. Hadoop Ecosystem主要项目介绍

          5. 实例: 用Hadoop实现网络爬虫

     第二周

          1. Pig简介

          2. Pig数据类型

          3. Pig的基本操作: group, join, order, distinct

          4. 如何编写Pig UDF

          5. Pig程序调试优化

          6. Pig ETL实例

     第三周

          1. Hive简介

          2. Hive SQL详解

          3. 如何编写Hive UDF

          4. Hive程序调试优化

          5. 用Hive做数据分析实例

     第四周

          1. Apache Software Foundation介绍

          2. Apache项目开发工具和流程: Jira, git/svn, maven/ant, eclipse

          3. 如何成为Apache contributor 

          4. 实例：如何搜索Apache代码，发现问题，解决问题，提交Apache代码
          
第三阶段：企业级Capstone项目
在经历两个月高强度学习与实战之后，每位学员将被分配相应的项目目标并在老师的指导下完成。两位主讲老师将以Manager的身份监督引导学员完成各自项目。



项目设计的例子涉及：

Cloudacl公司数据挖掘与分析系统

开放数据挖掘与分析系统

Apache Pig和Apache Hive开源项目Contribution

  Alluxio 开源项目Contribution



*Capstone 项目方向会实时更新，欢迎大家及时查看课程主页。

成为Apache开源项目Contributor
在Apache多个开源项目的Committer的Daniel老师带领下，你将更加深入，细致的了解诸多Apache开源项目的原理，开发及其应用。同学们更可以通过Apache开源项目强化训练中完成的项目，提交自己的代码，成为Apache开源项目的Contributor。

公司实习-Capstone项目
      在经历两个月高强度学习与实战之后，每位学员将被分配相应的项目目标并在老师的指导下完成。两位主讲老师将以Manager的身份监督引导学员完成各自项目。并可以将完成项目作为实习经历写进自己的简历。项目设计的例子涉及：



基本的统计信息，报表

异常分析，某一天的数据量异常，如果寻找原因

建立数据仓库，用可视化工具进行数据探索

数据挖掘

Fix开源系统的Bug

打造最强简历
     * 完成第一个月的学习及项目之后，你可以将Design a Big Data Stock Platform写进简历中。

     * 完成第二个月的学习及项目之后，你将在拥有新的项目之后同时成为Apache的Contributor。

     * 完成第三个月的Capstone项目之后，你将拥有资格将本次经历写成为实习经历，放进简历中。课程最后部分项目设计，学员将被分成不同的Track，参考项目题目有：



基本的统计信息，报表

异常分析，某一天的数据量异常，如果寻找原因

建立数据仓库，用可视化工具进行数据探索

数据挖掘

Fix开源系统的Bug

      本课程的项目将会使用真实的大数据，不是Demo，让学生真实体验实际运营的系统。通过这个课程，大多数同学可以成为Apache Contributor。
      
      
背景介绍+项目展示+开发环境配置+Apache Kafka+Apache Cassandra
介绍Big Data的背景，生态圈及相关的开源项目和技术:

- Data Storage: Apache HBase, Apache Cassandra, etc
- Data Transportation: Apache Kafka, RabbitMQ, NSQ, ZeroMQ, etc
- Data Processing: Apache Hadoop, Apache Spark, etc
- Resource Management: Apache Mesos, Kubernetes, etc
- Container: Docker, Docker Machine, Docker Swarm, etc

Big Data Platform项目展示:

- 目标功能
- 介绍应用的技术栈
- 介绍技术选型原则及技巧

开发环境配置:

- Docker + Docker Machine

Apache Kafka:

- Apache Kafka介绍
- Apache Kafka内部实现细节

Apache Cassandra:

- Apache Cassandra介绍
- Apache Cassandra内部实现细节

Redis+NodeJS+Apache Spark+ Apache Mesos+系统部署+系统运维
Redis

- Redis介绍
- Redis内部实现细节

NodeJS

- NodeJS介绍及相关框架

Apache Spark

- Apache Spark介绍
- Apache Spark内部实现细节

Apache Mesos

- Apache Mesos介绍
- Apache Mesos内部实现细节
- Apache Mesos相关框架

系统部署

- AWS + Terraform + Chef/Puppet/Ansible/Salt

系统运维

- 系统运维相关工具介绍
